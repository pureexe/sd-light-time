# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99826 -m v2_all_everett_dining1_exr_oldgt -c 50,40,30,20,10,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99828 -m v2_all_everett_dining1_exr_newgt -c 50,40,30,20,10,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99998 -m v2_all_everett_dining1_divide -c 50,40,30,20,10,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49


# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99828 -m v2_all_14n_copyroom10_light3_exr_newgt -c 50,40,30,20,10,1,5,15,25,35,45,55,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49



# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99828 -m single_everett_dining1_exr_newgt -c 40

# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99828 -m all_14n_copyroom10_light3_exr_newgt -c 40,30,20,10,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99828 -m all_14n_copyroom10_light4_exr_newgt -c 40,30,20,10,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99828 -m all_14n_copyroom10_light20_exr_newgt -c 40,30,20,10,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42

# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99998 -m all_14n_copyroom10_light3_divide -c 15,10,5,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99998 -m all_14n_copyroom10_light3_divide -c 15,10,5,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99998 -m all_14n_copyroom10_light3_divide -c 15,10,5,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25


# all_14n_copyroom10_light3_exr_newgt
# all_14n_copyroom10_light4_exr_newgt
# all_14n_copyroom10_light20_exr_newgt


# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99826 -m all_14n_copyroom1_exr_oldgt -c 40,30,20,10,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99828 -m all_14n_copyroom1_exr_newgt -c 40,30,20,10,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99998 -m all_14n_copyroom1_divide -c 15,10,5,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14

# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99826 -m all_everett_kitchen4_exr_oldgt -c 40,30,20,10,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99828 -m all_everett_kitchen4_exr_newgt -c 40,30,20,10,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,32,33,34,35,36,37,38,39,40,41,42
# bin/siatv100 src/20250221_optmized_shading_exr/val_ddim.py -i 99998 -m all_everett_kitchen4_divide -c 15,10,5,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14


import os
import lightning as L
import torch
import argparse 
#from LineNotify import LineNotify
import argparse
from constants import FOLDER_NAME

from constants import OUTPUT_MULTI, DATASET_ROOT_DIR, DATASET_VAL_DIR, DATASET_VAL_SPLIT
from sddiffusionface import SDDiffusionFace, ScrathSDDiffusionFace, SDWithoutAdagnDiffusionFace, SDOnlyAdagnDiffusionFace, SDOnlyShading, SDDiffusionFaceNoShading, SDDiffusionFace5ch, SDDiffusionFaceNoBg

from datasets.DDIMDiffusionFaceRelightDataset import DDIMDiffusionFaceRelightDataset

MASTER_TYPE = 16
CHECKPOINT_FOLDER_NAME = "20250221_optmized_shading_exr"


parser = argparse.ArgumentParser()
parser.add_argument("-i", "--version", type=str, default="2")
parser.add_argument("-m", "--mode", type=str, default="face_left,face_right")
parser.add_argument("-g", "--guidance_scale", type=str, default="1")
parser.add_argument("-c", "--checkpoint", type=str, default="lastest")

args = parser.parse_args()

# we validate 4  model whcih are 
# all
# scrath
# controlnet (SD without adagan)
# adagan


NAMES = {
    99826: 'newshading_oldgt',
    99828: 'newshading_newgt',
    99998: 'divideshading_oldgt',
}
METHODS = {
    99826: 'default',
    99828: 'default',
    99998: 'default',
}
CONDITIONS_CLASS = {
    99826: SDDiffusionFaceNoBg,
    99828: SDDiffusionFaceNoBg,
    99998: SDDiffusionFaceNoBg,
}
LRS = {
    99826: '1e-4',
    99828: '1e-4',
    99998: '1e-4',
}
DIRNAME = {
    99826: CHECKPOINT_FOLDER_NAME,
    99828: CHECKPOINT_FOLDER_NAME,
    99998: CHECKPOINT_FOLDER_NAME,
}
CHECKPOINTS = {
    99826: 20,
    99828: 20,
    99998: 20,
}

use_ab_background = []
use_shcoeff2 = []
use_only_light = []
use_no_light = [99826, 99828, 99998]
use_random_mask_background = []

def get_from_mode(mode):
    if mode == "single_everett_dining1_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/test", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/everett_dining1_single_light0.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"images" , "feature_types": []},  "a photorealistic image"
    if mode == "v2_all_14n_copyroom10_light3_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom10_all_light3.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"control_render_from_fitting_v2" , "feature_types": []},  "a photorealistic image"
    if mode == "v2_all_14n_copyroom10_light4_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom10_all_light4.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"control_render_from_fitting_v2" , "feature_types": []},  "a photorealistic image"
    if mode == "v2_all_14n_copyroom10_light20_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom10_all_light20.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"control_render_from_fitting_v2" , "feature_types": []},  "a photorealistic image"
    if mode == "v2_all_everett_dining1_divide":
        return "/data/pakkapon/datasets/multi_illumination/spherical/test", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/everett_dining1_all.json", "shadings_dir": "control_shading_from_fitting_v3_exr_divide", "backgrounds_dir": "images", "feature_types": []},  "a photorealistic image"
    if mode == "v2_all_everett_dining1_exr_oldgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/test", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/everett_dining1_all.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "images", "feature_types": []},  "a photorealistic image"
    if mode == "v2_all_everett_dining1_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/test", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/everett_dining1_all.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"control_render_from_fitting_v2" , "feature_types": []},  "a photorealistic image"
    if mode == "all_everett_kitchen4_divide":
        return "/data/pakkapon/datasets/multi_illumination/spherical/test", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/everett_kitchen4_all.json", "shadings_dir": "control_shading_from_fitting_v3_exr_divide", "backgrounds_dir": "images", "feature_types": []},  "a photorealistic image"
    if mode == "all_everett_kitchen4_exr_oldgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/test", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/everett_kitchen4_all.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "images", "feature_types": []},  "a photorealistic image"
    if mode == "all_everett_kitchen4_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/test", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/everett_kitchen4_all.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"control_render_from_fitting_v2" , "feature_types": []},  "a photorealistic image"
    if mode == "all_14n_copyroom1_divide":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom1_all.json", "shadings_dir": "control_shading_from_fitting_v3_exr_divide", "backgrounds_dir": "images", "feature_types": []},  "a photorealistic image"
    if mode == "all_14n_copyroom1_exr_oldgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom1_all.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "images", "feature_types": []},  "a photorealistic image"
    if mode == "all_14n_copyroom1_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom1_all.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"control_render_from_fitting_v2" , "feature_types": []},  "a photorealistic image"
    if mode == "all_14n_copyroom10_light3_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom10_all_light3.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"control_render_from_fitting_v2" , "feature_types": []},  "a photorealistic image"
    if mode == "all_14n_copyroom10_light4_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom10_all_light4.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"control_render_from_fitting_v2" , "feature_types": []},  "a photorealistic image"
    if mode == "all_14n_copyroom10_light20_exr_newgt":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom10_all_light20.json", "shadings_dir": "control_shading_from_fitting_v3_exr", "backgrounds_dir": "control_render_from_fitting_v2", "images_dir":"control_render_from_fitting_v2" , "feature_types": []},  "a photorealistic image"
    if mode == "all_14n_copyroom10_light3_divide":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom10_all_light3.json", "shadings_dir": "control_shading_from_fitting_v3_exr_divide", "backgrounds_dir": "images", "feature_types": []},  "a photorealistic image"
    if mode == "all_14n_copyroom10_light4_divide":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom10_all_light4.json", "shadings_dir": "control_shading_from_fitting_v3_exr_divide", "backgrounds_dir": "images", "feature_types": []},  "a photorealistic image"
    if mode == "all_14n_copyroom10_light20_divide":
        return "/data/pakkapon/datasets/multi_illumination/spherical/train", 100, DDIMDiffusionFaceRelightDataset,{"index_file":"/data/pakkapon/datasets/multi_illumination/spherical/index/14n_copyroom10_all_light20.json", "shadings_dir": "control_shading_from_fitting_v3_exr_divide", "backgrounds_dir": "images", "feature_types": []},  "a photorealistic image"
    else:
        raise Exception("mode not found")

def main():
    print("STARTING VALIDATION...")
    versions = [int(a.strip()) for a in args.version.split(",")]
    guidance_scales = [float(a.strip()) for a in args.guidance_scale.split(",")]
    #checkpoints = [int(a.strip()) for a in args.checkpoint.split(",")]
    checkpoints = []
    for checkpoint in args.checkpoint.split(","):
        checkpoint = checkpoint.strip()
        try:
            checkpoint = int(checkpoint)
        except:
            pass 
        checkpoints.append(checkpoint)
    modes = [a.strip() for a in args.mode.split(",")]

    print("version: ", versions)
    print("guidance_scales: ", guidance_scales)
    print("checkpoints: ", checkpoints)
    print("modes: ", modes)

    for mode in modes:
        for version in versions:
                ddim_class = CONDITIONS_CLASS[version]
                try:
                    for checkpoint in checkpoints:
                        dirname = DIRNAME[version]
                        if checkpoint == "lastest":
                            checkpoint = CHECKPOINTS[version]
                        if checkpoint == 0:
                            model = ddim_class(learning_rate=1e-4)
                            CKPT_PATH = None
                        else:
                            CKPT_PATH = f"output/{dirname}/multi_mlp_fit/lightning_logs/version_{version}/checkpoints/epoch={checkpoint:06d}.ckpt"
                            if not os.path.exists(CKPT_PATH):
                                print(f"Checkpoint not found: {CKPT_PATH}")
                                continue
                            model = ddim_class.load_from_checkpoint(CKPT_PATH)
                        # disable chromeball inpaint if exist
                        if hasattr(model, 'pipe_chromeball'):
                            del model.pipe_chromeball
                        model.eval() # disable randomness, dropout, etc...
                        model.disable_plot_train_loss()
                        for guidance_scale in guidance_scales:
                            #model.set_guidance_scale(guidance_scale)
                            #model.set_ddim_strength(guidance_scale) #temporary hack to feed the guidance ratio                        
                            #model.set_gaussain_strength(guidance_scale)  #temporary hack to feed the guidance ratio
                            output_dir = f"output/{FOLDER_NAME}/val_{mode}/{METHODS[version]}/{guidance_scale}/{NAMES[version]}/{LRS[version]}/chk{checkpoint}/"
                            # skip if output dir exist 
                            if os.path.exists(output_dir):
                                print(f"Skip {output_dir}")
                                continue
                            os.makedirs(output_dir, exist_ok=True)
                            print("================================")
                            print(output_dir)
                            print("================================")
                            trainer = L.Trainer(max_epochs=1000, precision=MASTER_TYPE, check_val_every_n_epoch=1, default_root_dir=output_dir, inference_mode=False, gradient_clip_val=0)
                            val_root, count_file, dataset_class, dataset_args, specific_prompt = get_from_mode(mode)
                            if type(count_file) == int:
                                split = slice(0, count_file, 1)
                            else:
                                split = count_file
                            if version in use_shcoeff2:
                                dataset_args['use_shcoeff2'] = True
                            if version in use_only_light:
                                dataset_args['feature_types'] = ['light']
                            if version in use_no_light:
                                dataset_args['feature_types'] = []
                            val_dataset = dataset_class(split=split, root_dir=val_root, specific_prompt=specific_prompt, **dataset_args)
                            val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)
                            trainer.test(model, dataloaders=val_dataloader, ckpt_path=CKPT_PATH)


                except Exception as e:
                    raise e

                                
if __name__ == "__main__":
    main()