{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../output/20240902/val_face_roll60_v2_scene5/1.0/depth/1e-4/chk319/lightning_logs/version_0\n",
      "../../output/20240902/val_face_roll60_v2_scene5/3.0/depth/1e-4/chk319/lightning_logs/version_0\n",
      "../../output/20240902/val_face_roll60_v2_scene5/5.0/depth/1e-4/chk319/lightning_logs/version_0\n",
      "../../output/20240902/val_face_roll60_v2_scene5/7.0/depth/1e-4/chk319/lightning_logs/version_0\n"
     ]
    }
   ],
   "source": [
    "#CONTROLS = ['both','depth']\n",
    "CONTROLS = ['depth']\n",
    "GUIDANCES = ['1.0','3.0','5.0','7.0']\n",
    "for control in CONTROLS:\n",
    "   for guidance in GUIDANCES:\n",
    "        root_dir = f'../../output/20240902/val_face_roll60_v2_scene5/{guidance}/{control}/1e-4/chk319/lightning_logs/version_0'\n",
    "        input_dir = root_dir + '/crop_image'\n",
    "        output_dir = root_dir + f'/video_frame'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(root_dir)\n",
    "        for frame_id in range(60):\n",
    "            images = []\n",
    "            env_image = torchvision.io.read_image(root_dir + f'/target_ldr_envmap/00000_02{frame_id:03d}.jpg') / 255.0\n",
    "            # resize to 256x256\n",
    "            #env_image = torchvision.transforms.Resize((256, 256))(env_image)\n",
    "            env_image = torchvision.transforms.functional.resize(env_image, (256, 256))\n",
    "            images.append(env_image)\n",
    "            for face_id in range(10):\n",
    "                image = torchvision.io.read_image(input_dir + f'/{face_id:05d}_02{frame_id:03d}.jpg')  / 255.0\n",
    "                image = torchvision.transforms.functional.resize(image, (256, 256))\n",
    "                images.append(image)\n",
    "            # create image grid \n",
    "            grid = torchvision.utils.make_grid(images, nrow=4)\n",
    "            # save image\n",
    "            torchvision.utils.save_image(grid, output_dir + f'/{frame_id:03d}.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
