{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torchvision\n",
    "from PIL import Image \n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[envmap rotate] [face 10]\n",
    "[Black image]   [Ball]\n",
    "[envmap rotate] [face 10]\n",
    "[Black image]   [Ball]\n",
    "[envmap rotate] [face 10]\n",
    "[Black image]   [Ball]\n",
    "[envmap rotate] [face 10]\n",
    "[Black image]   [Ball]\n",
    "[envmap rotate] [face 10]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"../../output/20240703/val_rotate_envmap/vae5000/3e-4/chk179\"\n",
    "IMAGE_TYPE = ['light_x_minus','light_x_plus','light_y_minus', 'light_y_plus','light_z_minus', 'light_z_plus']\n",
    "AXIS = ['x','y','z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "def convert_to_grayscale_and_highlight(image):\n",
    "  \"\"\"\n",
    "  Converts an image to grayscale, finds the average brightness,\n",
    "  and sets pixels with matching grayscale values to red.\n",
    "\n",
    "  Args:\n",
    "      image: A PyTorch tensor of shape [3, 256, 256] representing an RGB image.\n",
    "\n",
    "  Returns:\n",
    "      A PyTorch tensor of shape [3, 256, 256] with the modified image.\n",
    "  \"\"\"\n",
    "\n",
    "  # Convert to grayscale using weighted average (BT.709 standard)\n",
    "  grayscale_transform = transforms.Grayscale(num_output_channels=1)\n",
    "  grayscale_image = grayscale_transform(image)\n",
    "\n",
    "  # Calculate average brightness\n",
    "  brightness = grayscale_image.max()\n",
    "\n",
    "  # Create a mask to select pixels with matching grayscale value\n",
    "  mask = (grayscale_image > brightness).float()\n",
    "\n",
    "  # Convert mask to a 3-channel tensor for element-wise multiplication\n",
    "  mask = mask.expand_as(image)\n",
    "\n",
    "  # Set matching pixels to red (assuming original image has uint8 dtype)\n",
    "  #red_channel = torch.zeros_like(image)  # Create a zero red channel\n",
    "  #red_channel[0] = 255\n",
    "  #red_channel.fill_(255)  # Fill with maximum red intensity (255 for uint8)\n",
    "  #modified_image = image * (1 - mask) + red_channel * mask\n",
    "  modified_image = image.copy()\n",
    "  for i in range(256):\n",
    "    for j in range(256):\n",
    "      print(grayscale_image[0,i,j], brightness)\n",
    "      if grayscale_image[0,i,j] >= brightness:\n",
    "        print(\"SET\")\n",
    "        modified_image[0,i,j] = 1.0\n",
    "        modified_image[1,i,j] = 0.0\n",
    "        modified_image[2,i,j] = 0.0\n",
    "#   modified_image[0,grayscale_image >= brightness] = 1.0\n",
    "#   modified_image[1,grayscale_image >= brightness] = 0.0\n",
    "#   modified_image[2,grayscale_image >= brightness] = 0.0\n",
    "\n",
    "  return modified_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AXIS[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_id:  0\n",
      "frame_id:  1\n",
      "frame_id:  2\n",
      "frame_id:  3\n",
      "frame_id:  4\n",
      "frame_id:  5\n",
      "frame_id:  6\n",
      "frame_id:  7\n",
      "frame_id:  8\n",
      "frame_id:  9\n",
      "frame_id:  10\n",
      "frame_id:  11\n",
      "frame_id:  12\n"
     ]
    }
   ],
   "source": [
    "image_type = IMAGE_TYPE[0]\n",
    "axis = AXIS[2]\n",
    "current_dir = f\"{ROOT_DIR}/{image_type}/lightning_logs/version_0/\"\n",
    "files = sorted(os.listdir(current_dir))\n",
    "files = [f for f in files if os.path.exists(os.path.join(current_dir,f,axis+'_ball','047.png'))][:30]\n",
    "for frame_id in range(48):\n",
    "    # create a row of envmap and images \n",
    "    rows = []\n",
    "    print(\"frame_id: \", frame_id)\n",
    "    for row_id in range(3):\n",
    "        # image row\n",
    "        row = []\n",
    "        scene_id = int(files[row_id*10].split(\"_\")[0])\n",
    "        # first add envmap picture \n",
    "        envmap = Image.open(f\"{current_dir}/{scene_id:05}_00000/{axis}_env/{frame_id:03d}.png\").resize((256,256))\n",
    "        #convert envmap to tensor\n",
    "        envmap = torchvision.transforms.ToTensor()(envmap)\n",
    "        row.append(envmap)\n",
    "\n",
    "        # for on 10 images \n",
    "        for image_id in range(0,10):\n",
    "            image = Image.open(f\"{current_dir}/{scene_id:05}_{image_id:05}/{axis}/{frame_id:03d}.png\").resize((256,256))\n",
    "            image = torchvision.transforms.ToTensor()(image)\n",
    "            row.append(image)\n",
    "        # concatenate row\n",
    "        rows += row\n",
    "        # ball row\n",
    "        row = []\n",
    "        #first ball is blank image\n",
    "        row.append(torch.zeros(3, 256, 256).to(torch.uint8))\n",
    "        for image_id in range(0,10):\n",
    "            try:\n",
    "                image = Image.open(f\"{current_dir}/{scene_id:05}_{image_id:05}/{axis}_ball/{frame_id:03d}.png\").resize((256,256))\n",
    "                image = torchvision.transforms.ToTensor()(image)\n",
    "                #image = convert_to_grayscale_and_highlight(image)\n",
    "            except:\n",
    "                image = torch.zeros(3, 256, 256).to(torch.uint8)\n",
    "            row.append(image)\n",
    "        rows += row\n",
    "    # makegrid from rows with 11 columns per row \n",
    "    frame_image = torchvision.utils.make_grid(rows,nrow=11)\n",
    "    # save image\n",
    "    output_dir = f\"{current_dir}/../frames_{axis}\"\n",
    "    os.makedirs(output_dir,exist_ok=True)\n",
    "    torchvision.utils.save_image(frame_image,f\"{output_dir}/{frame_id:03d}.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
