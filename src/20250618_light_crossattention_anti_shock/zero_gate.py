# zero gate is a is use for re-intialize model weight without affecting the output

def zero_transformer_model_2d(Transformer2DModel: block):
    pass

    # self.num_attention_heads
    # self.in_channels = in_channels
    # self.out_channels =
    # self.config.cross_attention_dim
    # self.config.norm_num_groups
    # self.use_linear_projection
    # self.config.only_cross_attention
    # self.config.upcast_attention
    # self.config.attention_type
     
def zero_resblock_2d(ResnetBlock2D block):
    pass
