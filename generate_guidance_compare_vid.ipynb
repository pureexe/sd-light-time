{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import skimage\n",
    "import torchvision \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHODS = ['dino2','slim','vae']\n",
    "CHKS = ['chk39','chk59']\n",
    "GUIDANCES = ['g1.00','g2.00','g3.00','g4.00','g5.00']\n",
    "FACES = list(range(8))\n",
    "IMAGES = list(range(48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chk in CHKS:\n",
    "    for face in FACES:\n",
    "        for image in IMAGES:\n",
    "            for method in METHODS:\n",
    "                for guidance in GUIDANCES:\n",
    "                    img = torchvision.io.read_image(f'output/20240703/val_video_gudiance/{method}/5e-5/{chk}/{guidance}/lightning_logs/version_0/face/step000000/{guidance}/{face}/{image:3d}.png')\n",
    "                    # resize to 256x256 using torchvision\n",
    "                    img = torchvision.transforms.functional.resize(img, (256, 256))\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
